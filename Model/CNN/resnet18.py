# -*- coding: utf-8 -*-
"""Resnet18.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/144zsCw9dbqTYIs8pSR9oqWfcw8PhA0W2
"""

import os
import cv2
import random
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
import torch
import torch.nn as nn
import torchvision.models as models
from torchvision.models.resnet import BasicBlock, Bottleneck, conv1x1, conv3x3, _resnet

from google.colab import drive
drive.mount('/content/drive')

# Define a function to load data
def load_data(data_dir, target_size=(224, 224), max_frames_per_video=10):
    data = []
    labels = []
    label_to_index = {}
    index = 0
    for label in os.listdir(data_dir):
        label_dir = os.path.join(data_dir, label)
        label_to_index[label] = index
        for video_folder in os.listdir(label_dir):
            frames = []
            video_path = os.path.join(label_dir, video_folder)
            for frame_file in sorted(os.listdir(video_path))[:max_frames_per_video]:
                frame_path = os.path.join(video_path, frame_file)
                frame = cv2.imread(frame_path)
                frame = cv2.resize(frame, target_size)
                frames.append(frame)
            if len(frames) < max_frames_per_video:
                frames.extend([np.zeros_like(frames[0])] * (max_frames_per_video - len(frames)))
            data.append(frames)
            labels.append(index)
        index += 1
    return np.array(data), np.array(labels), label_to_index


# Load training and testing data
train_data, train_labels, label_to_index = load_data("/content/drive/MyDrive/Dataset_Full/Train")
test_data, test_labels, _ = load_data("/content/drive/MyDrive/Dataset_Full/Test")

# Reshape train_data and test_data
train_data = train_data.reshape((-1, 224, 224, 3))
test_data = test_data.reshape((-1, 224, 224, 3))

# Verify data shapes
print("Shape of train_data:", train_data.shape)
print("Shape of train_labels:", train_labels.shape)
print("Shape of test_data:", test_data.shape)
print("Shape of test_labels:", test_labels.shape)

# Encode string labels to integers
label_encoder = LabelEncoder()
train_labels_encoded = label_encoder.fit_transform(train_labels)
test_labels_encoded = label_encoder.transform(test_labels)

# Shuffle training data based on the length of label array
random.seed(42)
idx = list(range(len(train_labels_encoded)))
random.shuffle(idx)
train_data = train_data[idx]
train_labels_encoded = train_labels_encoded[idx]

# Load pre-trained ResNet model
resnet_model = models.resnet18(pretrained=True)

# Freeze the layers of the pre-trained model
for param in resnet_model.parameters():
    param.requires_grad = False

# Modify the last layer for our classification task
num_ftrs = resnet_model.fc.in_features
resnet_model.fc = nn.Sequential(
    nn.Linear(num_ftrs, 64),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(64, 2),
    nn.Softmax(dim=1)
)

# Convert the model to be compatible with GPU, if available
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
resnet_model = resnet_model.to(device)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.001)

# Train the model
num_epochs = 10
batch_size = 80
for epoch in range(num_epochs):
    resnet_model.train()
    running_loss = 0.0
    for i in range(0, len(train_data), batch_size):
        inputs = torch.tensor(train_data[i:i + batch_size]).permute(0, 3, 1, 2).float().to(device)
        labels = torch.tensor(train_labels_encoded[i:i + batch_size]).to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward + backward + optimize
        outputs = resnet_model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)

    epoch_loss = running_loss / len(train_data)
    print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}")

# Evaluate the model on test data
resnet_model.eval()
test_predictions = []

# Evaluate the model on test data with consistent batch size
with torch.no_grad():
    for i in range(0, len(test_data), batch_size):
        inputs = torch.tensor(test_data[i:i + batch_size]).permute(0, 3, 1, 2).float().to(device)
        labels_batch = torch.tensor(test_labels_encoded[i:i + batch_size]).to(device)

        # Forward pass
        outputs = resnet_model(inputs)

        # Get predictions
        _, predicted = torch.max(outputs, 1)

        # Extend test predictions
        test_predictions.extend(predicted.cpu().numpy())

# Ensure that test predictions are sliced to match the number of test labels
test_predictions = test_predictions[:len(test_labels_encoded)]

# Convert test_labels_encoded to numpy array
test_labels_np = test_labels_encoded

# Generate classification report
print("Classification Report:")
print(classification_report(test_labels_np, test_predictions))

# Generate confusion matrix (heat map)
cm = confusion_matrix(test_labels_np, test_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_to_index.keys(), yticklabels=label_to_index.keys())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Save the model
torch.save(resnet_model.state_dict(), "/content/drive/MyDrive/Models/ResNet_Face_Detection.pth")