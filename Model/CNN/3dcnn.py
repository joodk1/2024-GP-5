# -*- coding: utf-8 -*-
"""3DCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ORS2ByX9SnjlgP_6cGU2wzaN6gkDtAYG
"""

import os
import cv2
import numpy as np
from tensorflow.keras.utils import Sequence
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix


class VideoDataGenerator(Sequence):
    def __init__(self, video_paths, labels, num_frames, height, width, batch_size=32, shuffle=True):
        self.video_paths = video_paths
        self.labels = labels
        self.num_frames = num_frames
        self.height = height
        self.width = width
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len(self.video_paths))
        if self.shuffle:
            np.random.shuffle(self.indexes)

    def __len__(self):
        return int(np.floor(len(self.video_paths) / self.batch_size))

    def __getitem__(self, index):
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
        video_paths_temp = [self.video_paths[k] for k in indexes]
        X, y = self._data_generation(video_paths_temp)
        return X, y

    def _data_generation(self, video_paths_temp):
        X = np.empty((self.batch_size, self.num_frames, self.height, self.width, 3), dtype=np.float32)
        y = np.empty((self.batch_size), dtype=int)

        for i, video_path in enumerate(video_paths_temp):
            cap = cv2.VideoCapture(video_path)
            frames = []
            for _ in range(self.num_frames):
                ret, frame = cap.read()
                if not ret:
                    break
                frame = cv2.resize(frame, (self.width, self.height))
                frames.append(frame)
            cap.release()

            if len(frames) == self.num_frames:
                X[i,] = np.stack(frames, axis=0)
                y[i] = self.labels[np.where(np.array(self.video_paths) == video_path)[0][0]]

        return X, y


    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)

def load_video_paths_and_labels(base_path):
    video_paths = []
    labels = []
    class_labels = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]
    label_to_index = {label: idx for idx, label in enumerate(class_labels)}

    for class_label in class_labels:
        class_path = os.path.join(base_path, class_label)
        video_files = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]

        video_paths.extend(video_files)
        labels.extend([label_to_index[class_label]] * len(video_files))

    return video_paths, np.array(labels)

# Define constants
num_frames = 10
height = 299
width = 299
batch_size = 32

# Specify the path to the dataset
train_base_path = "/content/drive/MyDrive/other/Dataset/Train"
test_base_path = "/content/drive/MyDrive/other/Dataset/Test"

# Load video paths and labels
train_video_paths, train_labels = load_video_paths_and_labels(train_base_path)
train_paths, val_paths, train_labels, val_labels = train_test_split(train_video_paths, train_labels, test_size=0.2, random_state=42)

# Initialize data generators
train_gen = VideoDataGenerator(train_paths, train_labels, num_frames, height, width, batch_size=batch_size, shuffle=True)
val_gen = VideoDataGenerator(val_paths, val_labels, num_frames, height, width, batch_size=batch_size, shuffle=False)

# Define input shape
input_shape = (num_frames, height, width, 3)

# Define the model
model = Sequential([
    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape),
    MaxPooling3D(pool_size=(2, 2, 2)),
    Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),
    MaxPooling3D(pool_size=(2, 2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_gen, epochs=10, validation_data=val_gen)

# Evaluate the model
y_pred = model.predict(test_video_data)
y_pred_binary = (y_pred > 0.5).astype(int)

# Classification report
print(classification_report(test_labels, y_pred_binary))

# Plot confusion matrix
cm = confusion_matrix(test_labels, y_pred_binary)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap='Greens', xticklabels=['Authentic', 'Manipulated'], yticklabels=['Authentic', 'Manipulated'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()


# Plot training history
plt.plot(history.history['accuracy'], label='accuracy', color='green', linestyle='-', marker='o')
plt.plot(history.history['val_accuracy'], label='val_accuracy', color='darkgreen', linestyle='--', marker='x')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Save the model
model.save("/content/drive/MyDrive/Dataset/Models/3DCNN.h5")

# Load test video paths and labels
test_video_paths, test_labels = load_video_paths_and_labels(test_base_path)

# Initialize test data generator
test_gen = VideoDataGenerator(test_video_paths, test_labels, num_frames, height, width, batch_size=1, shuffle=False)

# Predict the test set
y_pred = model.predict(test_gen)
y_pred_binary = (y_pred > 0.5).astype(int).reshape(-1)  # Adjust based on your model's output layer and activation


# Generate classification report
print(classification_report(test_labels, y_pred_binary))

# Generate and plot confusion matrix
cm = confusion_matrix(test_labels, y_pred_binary)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap='Greens', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Plot training history
plt.plot(history.history['accuracy'], label='accuracy', color='green', linestyle='-', marker='o')
plt.plot(history.history['val_accuracy'], label='val_accuracy', color='darkgreen', linestyle='--', marker='x')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Save the model
model.save("/content/drive/MyDrive/Dataset/Models/3DCNN.h5")