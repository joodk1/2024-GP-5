# -*- coding: utf-8 -*-
"""Inception.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TyM-KG22kWxEzmwoF3X-T4W8x65c5bH3
"""

import os
import cv2
import random
import numpy as np
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

def load_data(data_dir, target_size=(299, 299), max_frames_per_video=10):
    data = []
    labels = []
    label_to_index = {}
    index = 0
    for label in os.listdir(data_dir):
        label_dir = os.path.join(data_dir, label)
        label_to_index[label] = index
        for video_folder in os.listdir(label_dir):
            frames = []
            video_path = os.path.join(label_dir, video_folder)
            for frame_file in sorted(os.listdir(video_path))[:max_frames_per_video]:
                frame_path = os.path.join(video_path, frame_file)
                frame = cv2.imread(frame_path)
                frame = cv2.resize(frame, target_size)
                frames.append(frame)
            if len(frames) < max_frames_per_video:
                frames.extend([np.zeros_like(frames[0])] * (max_frames_per_video - len(frames)))
            data.append(frames)
            labels.append(index)
        index += 1
    return np.array(data), np.array(labels), label_to_index

# Load training and testing data
train_data, train_labels, label_to_index = load_data("/content/drive/MyDrive/Dataset_Faces/Train")
test_data, test_labels, _ = load_data("/content/drive/MyDrive/Dataset_Faces/Test")

# Reshape train_data and test_data
train_data = train_data.reshape((-1, 299, 299, 3))
test_data = test_data.reshape((-1, 299, 299, 3))

# Verify data shapes
print("Shape of train_data:", train_data.shape)
print("Shape of train_labels:", train_labels.shape)
print("Shape of test_data:", test_data.shape)
print("Shape of test_labels:", test_labels.shape)

# Encode string labels to integers
label_encoder = LabelEncoder()
train_labels_encoded = label_encoder.fit_transform(train_labels)
test_labels_encoded = label_encoder.transform(test_labels)

# Shuffle training data based on the length of label array
random.seed(42)
idx = list(range(len(train_labels_encoded)))
random.shuffle(idx)
train_data = train_data[idx]
train_labels_encoded = train_labels_encoded[idx]

# Create reverse mapping from index to label
index_to_label = {v: k for k, v in label_to_index.items()}

# Load InceptionV3 model pre-trained on ImageNet
base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))

# Add a global spatial average pooling layer
model = Sequential()
model.add(base_model)
model.add(GlobalAveragePooling2D())

# Add a dense layer
model.add(Dense(len(label_to_index), activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_data, train_labels_encoded, epochs=10, batch_size=32, validation_split=0.2)

# Plot loss and accuracy over epochs
plt.figure(figsize=(12, 5))

# Plot training & validation loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot training & validation accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

# Evaluate the model on test data
test_predictions = model.predict(test_data)
test_predictions = np.argmax(test_predictions, axis=1)

# Convert numerical predictions back to string labels for classification report
test_predictions_labels = label_encoder.inverse_transform(test_predictions)

# Majority voting aggregation
test_predictions_labels_reshaped = test_predictions_labels.reshape((-1, 10))
video_labels = np.array([np.bincount(predictions).argmax() for predictions in test_predictions_labels_reshaped])

# Generate classification report
print("Classification Report:")
print(classification_report(test_labels, video_labels))

# Generate confusion matrix (heat map)
cm = confusion_matrix(test_labels, video_labels)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_to_index.keys(), yticklabels=label_to_index.keys())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Save the model
model.save("/content/drive/MyDrive/Models/InceptionV3")